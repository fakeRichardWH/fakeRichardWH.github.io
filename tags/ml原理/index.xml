<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>ML原理 - Tag - fakeRichardWH的个人网站</title>
        <link>http://localhost:1313/tags/ml%E5%8E%9F%E7%90%86/</link>
        <description>ML原理 - Tag - fakeRichardWH的个人网站</description>
        <generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 26 Jan 2022 19:25:43 &#43;0800</lastBuildDate><atom:link href="http://localhost:1313/tags/ml%E5%8E%9F%E7%90%86/" rel="self" type="application/rss+xml" /><item>
    <title>XGBOOST</title>
    <link>http://localhost:1313/post/ml02/</link>
    <pubDate>Wed, 26 Jan 2022 19:25:43 &#43;0800</pubDate>
    <author>Author</author>
    <guid>http://localhost:1313/post/ml02/</guid>
    <description><![CDATA[XGBoost 由于它计算的准而且快，所以用在各大比赛当中使用的多，不要迷信深度学习 xGBoost = extreme + GBDT = extreme + Gradient + BoostDT Boosting -&gt; Boosting DT -&gt; gradient BDT -&gt; 使用了一阶梯度信息 所谓的最优函数]]></description>
</item><item>
    <title>朴素贝叶斯及监督学习模型的分类</title>
    <link>http://localhost:1313/post/ml01/</link>
    <pubDate>Wed, 26 Jan 2022 19:25:43 &#43;0800</pubDate>
    <author>Author</author>
    <guid>http://localhost:1313/post/ml01/</guid>
    <description><![CDATA[朴素贝叶斯 目标: 解决的是多分类问题. 假设训练数据为$(X,Y)$,其中X为属性集合,Y为类别标记,这时候我们需要对新产生的样本x,进行类别预]]></description>
</item></channel>
</rss>
